---
title: "Statistical Inference Course Project"
author: "Mogens Yde-Andersen"
date: "26. jul. 2015"
output:
  word_document: default
  md_document:
    toc: yes
  pdf_document:
    toc: yes
  html_document:
    theme: united
    toc: yes
---
###Overview

In this statistical inference course project, I use simulation to explore inference and do simple inferential data analysis. The project consists of an simulation exercise and a basic inferential data analysis and an appendix.

###1. Simulation exercise

Investigate the exponential distribution and compare it with the Central Limit Theorem.

###1.1. Simulations

3 simulation exercises are conducted. In each exercise each simulation is done 1000 times. In each simulation 40 exponentials are randomly generated with the R code "rexp(n, lambda)". The 1. simulation take the mean of the 40 random exponentials in each of the 1000 simulations and place it in the mean1000 variable. The 2.simulation take the variance of the 40 random exponentials in each of the 1000 simulations and place it in the var1000 variable. The 3.simulation run 1000 simulations generating 40 exponentials each. Place the 40000 random exponentials in the rexp40000 variable.

Assumptions in all 3 simulations exercises are that the random numbers are generated by "set.seed(1234)" to make the simulation exercises reproducible and that the rate parameter for the exponential function is $\lambda$ = 0.2.

###1.2 Sample Mean versus Theoretical Mean

Show the sample mean and compare it to the theoretical mean of the distribution.

```{r chunk1_Mean, echo=FALSE, cache=TRUE, fig.width=8, fig.height=5}
##Gen. af 1000 reproducible simulations of 40 exp. dist. samples - taking the mean of each sample
set.seed(1234); mean1000=NULL
for (i in 1:1000) mean1000 = c(mean1000, (mean(rexp(40, 0.2))))
##Gen. of cum. mean of means, as no. of simulations goes up to 1000
n <- (1:1000); cummean1000 <- cumsum(mean1000)/n
##Gen. of panel with 2 plots: Hist. of mean dist. and Graph of cumm. sample mean approx. theo. mean
par(mfrow = c(1,2), mar = c(4,4,3,1), oma = c(0,0,2,0))
hist(mean1000, col="deepskyblue",main="Fig.1: Histogram of means of 1000 samples", xlab="Samples' means")
abline(v = 5, lwd=3, col="white"); abline(v = 4.974239, lwd=2, lty=2, col="red")
plot(cummean1000, type="l",col="deepskyblue", xlab="Number of simulations", ylab="Cumulated sample mean", main="Fig.2: Cumulated sample mean"); abline(h = 5, lwd=2, col="darkblue")
```

The theoretical mean of an exponential distribution = 1/lambda = 1/0.2 = 5.

The blue figure 1 shows the distribution of the outcome "mean" of each of a 1000 simulations, where each simulation has produced an outcome mean from 40 randomly generated data points from the function (rexp) in R. The white line shows the theoretical mean 5 of the distribution, where as the dotted red line shows the cumulated mean of the sample means of 4.974239.  (See calc. below.)

Even though the left "shoulder" is a little bit bigger, the sampled mean distribution centers elegantly around the theoretical mean.

Figure 2 shows the development of the cumulated mean, as the number of simulations goes toward 1000. The graph shows how the cumulated mean (of 4.97, see Appendix A1) approximates the theoretical mean of the underlying exponential distribution.

###1.3 Sample Variance versus Theoretical Variance

Show how variable the sample is (via variance) and compare it to the theoretical variance of the distribution.

```{r chunk2_Variance, echo=FALSE, cache=TRUE, fig.width=8, fig.height=5}
##Gen. af 1000 reproducible simulations of 40 exp. dist. samples - taking the variance of each sample
set.seed(1234); var1000=NULL
for (i in 1:1000) var1000 = c(var1000, (var(rexp(40, 0.2))))
##Gen. of cumulated mean of variances, as no. of simulations goes up to 1000
n <- (1:1000); cumvar1000 <- cumsum(var1000)/n
##Gen. of a panel w. 2 plots: Hist. of variance dist. and Graph of cumm. sample variance approx. theo. variance
par(mfrow = c(1,2), mar = c(4,4,3,1), oma = c(0,0,2,0))
hist(var1000, col="lemonchiffon1",main="Fig.3: Histogram of 1000 samples' variances", xlab="Samples' variances (Var[X])")
abline(v = 25, lwd=4, col="darkblue"); abline(v = 24.37801, lwd=3,lty=2, col="red")
plot(cumvar1000, type="l",col="deepskyblue", xlab="Number of simulations", ylab="Cumulated sampled variance", main="Fig.4: Cumulated sample variance")
abline(h = 25, lwd=2, col="darkblue")
```

Theoretical variance of an exponential distribution = 1/(lambda^2) = 1/(0.2^2) = 25.

The yellow figure 3 shows the distribution of the outcome "variance" of each a 1000 simulations, where each simulation has produced an outcome variance from 40 randomly generated datapoints from the function (rexp) in R. The blue line shows the theoretical variance of the distribution. The dotted red line shows the cumulated mean of the sample variances of 24.37801. (See calc. in Appendix A2.)

The sampled variance distribution centers around the theoretical variance, but has a bigger left "shoulder." If the number of simulations were to be increased, the distribution of observed variances would center better around the theoretical variance mean, and the cumulated mean of the variances (of 24.38, se Appendix A2) will approximate the theoretical variance mean.

Figure 4 shows the development of the cumulated mean of variance, as the number of simulations goes toward 1000. The graph shows how the cumulated mean of variance approximates the theoretical variance of the underlying exponential distribution.

###1.4 Distribution

Show that the distribution is approximately standard normal.

```{r chunk3_Distribution, echo=FALSE, cache=TRUE, fig.width=8, fig.height=6}
##Generation af 1000 reproducible simulations of 40 exponential distribution samples
set.seed(1234); rexp40000=NULL; for (i in 1:1000) rexp40000 = c(rexp40000, (rexp(40, 0.2)))
##Generation of cumulated mean of 40 random exponentials, as the number of simulation goes up to 1000
n <- 1:40000;cumrexp40000 <- cumsum(rexp40000)/n
##Generation af a panel with room for 4 plots
par(mfrow = c(1,2), mar = c(4,4,3,1), oma = c(0,0,2,0))
##Generation of a histogram of the distribution of the exponential samples' data points
hist(rexp40000, col="palegreen", main="Fig.5: Histogram of 40000 random exp. obs",xlab="Number of observations")
abline(v = 5, lwd=3, col="yellow");abline(v = 4.974239, lwd=1,lty=2, col="red")
##Generation of graf that shows the appromation of the cumulated sample mean of exponentials towards the theoretical mean
plot(cumrexp40000, type="l",col="deepskyblue", xlab="Number of observations", ylab="Cumulated sample mean", main="Fig.6: Cumulated mean of exponential obs."); abline(h = 5, lwd=2, col="darkblue")
```

The Central Limit Theorem (CLT) states that the distribution of averages of iid variables becomes that of a standard normal distribution as the sample size increases. That is (Estimat of X(n) - mean of estimate)/Std. Error of Estimate
has a distribution like that of a standard normal distribution for large numbers of n.

An approximation of the measured sample mean is N(mean,(sd^2)/n).

The green figure 5 shows the distribution of a 1000 simulations, where each simulation has randomly generated 40 datapoints from the function (rexp) in R. The 40.000 data points show the profile of a exponential distribution. The yellow line shows, where the theretical mean for exp(x) distribution is. The dotted red line shows the sample mean.
 
The observed distribution is heavily skewed to left due to the nature of the exponential function. It doesn't follow the bell-shaped curve of a normal distribution like figure 1 and 3. Figure 6 shows how quickly the cumulated sample mean centers around the theoretical mean 5.

If the distribution of the observations in variable mean1000 (Fig.1) and in variable var1000 (Fig.3) can be described by a normal distribution X ~ (mu, sigma^2), then a standarnd distribution Z vil follow the equation Z = (x-mu)/sigma ~ N(0,1). If Z is true, then X = mu + sigma*Z ~N(mu, sigma^Â¨2). This can be approximated with N(mean,(sd^2)/n).

Figure 1 and figure 2 show that the sample mean approximates 5, as the number of simulations over the underlying exponential distribution increases. Similarly does figure 3 and figure 4 show that the sample variance approximates 25, as the number of the same simulations over the same underlying distribution increases as well.

Therefore a distribution of averages can be described as X ~ N(5,25). According til CLT, if X ~ N(5,25) is true, then a distribution Z can be described as a standard normal distribution by the equation Z = (X-5)/25 ~ N(0,1). If Z is true, then X = 5 + 25*Z ~ N(5,25). Therefore the predicted mean of the distribution of averages shall lie in the following confidence interval of 97,5%

Since the sample mean of 4.974 (See Appendix A3) lies within the predicted 97,5% confidence interval [4.951,5.049] (See Appendix A3)), then the Central Limit Theorem holds, and the distribution of averages is approximately standard normal.

###2. Basic inferential data analysis

###2.1 Load the ToothGrowth data and perform some basic exploratory data analyses

```{r chunk4, echo=FALSE, fig.width=7, fig.height=6}
##Load thte ToothGrowth dataset and unfold the dataset in a boxplot
data(ToothGrowth)
boxplot(len ~ supp + dose, ToothGrowth, col=c("deepskyblue","palegreen1"), xlab = "Vitamin C delivered as orange juice (OJ) or as ascorbic acid (VC) in dosage of 0.5, 1.0 or 2.0 mg", ylab = "Guinea pig tooth growth (length units)", main = "Fig.7: Results of guinea pig tooth growth experiment")
```

As figure 7 shows, the dataset ToothGrowth contains the measured growth of the teeth of 60 guinea pigs grouped into 6 due to received supplement type and dosage.

###2.2 Provide a basic summary of the data

The ToothGrowth dataset contains the response in the length of odontoblasts (teeth) in each of 10 guinea pigs at each of three dose levels of Vitamin C (0.5, 1, and 2 mg) with each of two delivery methods (orange juice (OJ) or ascorbic acid (VC)).

The ToothGrowth dataset format is a data frame with 60 observations on 3 variables; 1) "len", a numeric variable for tooth growth length, 2) "supp", a factor variable for supplement type (OJ or VC) and 3) "dose",	a numeric variable for dose in milligrams.

The observed means and variances of the guinea pig tooth growth length in each groups of 10 guinea pigs per supplement and per dosage are seen in the appendix A4.

###2.3 Use confidence intervals and/or hypothesis tests to compare tooth growth by supp and dose.

The hypothesis is that orange juice is better than ascorbin acid at all measured dosages for guinea pig tooth growth length (tgl).

$H_01$: E[X$_(tgl.oj05)$] â¥ E[X$_(tgl.vc05)$] => H01: E[X$_(tgl.oj05)$] - E[X$_(tgl.vc05)$] â¥ 0

$H_a1$: E[X$_(tgl.oj05)$] < E[X$_(tgl.vc05)$] => H01: E[X$_(tgl.oj05)$] - E[X$_(tgl.vc05)$] < 0

$H_02$: E[X$_(tgl.oj10)$] â¥ E[X$_(tgl.vc10)$] => H01: E[X$_(tgl.oj10)$] - E[X$_(tgl-vc10)$] â¥ 0

$H_a2$: E[X$_(tgl.oj10)$] < E[X$_(tgl.vc10)$] => H01: E[X$_(tgl.oj10)$] - E[X$_(tgl-vc10)$] < 0

$H_03$: E[X$_(tgl.oj20)$] â¥ E[X$_(tgl.vc20)$] => H01: E[X$_(tgl.oj20)$] - E[X$_(tgl-vc20)$] â¥ 0

$H_a3$: E[X$_(tgl.oj20)$] < E[X$_(tgl.vc20)$] => H01: E[X$_(tgl.oj20)$] - E[X$_(tgl-vc20)$] < 0

The t-test will test the 3 null hypotheses against their alternatives. See calculations in the appendix A5.

###2.4 State your conclusions and the assumptions needed for your conclusions

Assumptions:
The tooth growth length of each guinea pig is the measured length difference at the end and at the start of the experiment. That is repeat measurement, and thus the data shall be treated in at an individual level, and the t-test er calculated with paired=TRUE.

Conclusions:

$H_01$ versus $H_a1$:
Since the t-statistic = 2.98 in the t-test lies within 95% confidence interval of [1.26,9.24], and since the confidence interval is positive, i fail to reject the $H_01$ hypothesis. This hypothesis is broken into 3 sub-hypotheses.

$H_02$ versus $H_a2$:
Since the t-statistic = 3.37 in the t-test lies within 95% confidence interval of [1.95,9.91], and since the confidence interval is positive, i fail to reject the $H_02$ hypothesis.

$H_03$ versus $H_a3$:
The t-statistic = -0.0426 in the t-test lies within 95% confidence interval of [-4.33,4.17]. But since the confidence interval contains 0, i con not rule out that $H_a3$ is true, but i fail to reject the $H_03$ hypothesis.

Orange juice as supplement in dosage 0.5 mg and 1.0 mg has a better impact on guinea pig tooth growth than ascorbin acid. In dosage 2.0 mg it is unproven that either orange juice or ascorbin acid is better at growing guinea pig teeth. Orange juice is not proven to bebetter than ascorbin acid at all dosages.

###Appendix

A1: Calculation of the cumulated mean of the 1.000 samples' means

```{r chunk5, echo=FALSE}
mean(mean1000)
```

A2: Calculation of the cumulated mean of variance of the 1.000 samples' variances

```{r chunk6, echo=FALSE}
mean(var1000)
```

A3: Calculation of the sample mean and of the 97,5% confidence interval

```{r chunk7, echo=FALSE}
##Calculating 97,5% confidence interval and Calculating sample mean of (rexp40000) - mean of 40000 exp. data points
5+c(-1,1)*(25/1000)*qnorm(.975); mean(rexp40000)
```

A4: Extracting the observed means of the guinea pig tooth growth length in each groups of 10 guinea pigs per supplement and per dosage are

```{r chunk8, echo=FALSE, cache=TRUE}
##Calculating the means and standard deviations for the guinea pig tooth growth length per supplement and per dosage
meanoverview <- aggregate(ToothGrowth[,1], list(ToothGrowth$supp, ToothGrowth$dose), mean)
colnames(meanoverview) <- c("Supplement","Dosage","Mean length")
sdoverview <- aggregate(ToothGrowth[,1], list(ToothGrowth$supp, ToothGrowth$dose), sd)
colnames(sdoverview) <- c("Supplement","Dosage","Standard deviation length")
overview <- cbind(meanoverview,sdoverview); overview[,c(1:3,6)]
```

A5: Creating the 6 relevant subgroups and calculating observed means and variances of the guinea pig tooth growth length in each groups of 10 guinea pigs per supplement and per dosage

```{r chunk9, echo=FALSE}
##Dividing the ToothGrowth data set into 6 subsets corresponding to the 6 groups and taking the relevant groups to t-test
oj <- subset(ToothGrowth, supp == 'OJ'); oj05 <- subset(oj, dose == 0.5); oj10 <- subset(oj, dose == 1.0); oj20 <- subset(oj, dose == 2.0)
vc <- subset(ToothGrowth, supp == 'VC'); vc05 <- subset(vc, dose == 0.5); vc10 <- subset(vc, dose == 1.0); vc20 <- subset(vc, dose == 2.0)
t.test(oj05$len, vc05$len, paired=TRUE)
t.test(oj10$len, vc10$len, paired=TRUE)
t.test(oj20$len, vc20$len, paired=TRUE)
```
